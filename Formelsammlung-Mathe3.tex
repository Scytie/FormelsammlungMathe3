\documentclass[10pt,twocolumn,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[german]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{color}
\usepackage{enumitem}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}

\setlist{noitemsep}
\setlist[itemize]{leftmargin=*}
\setlist[itemize,1]{label=-}

\begin{document}
\begin{flushleft}

\textbf{Wahrscheinlichkeiten}

$P(A \cup B) = P(A) + P(B) - P(A \cap B)$\\
A und B unabhängig: $P(A \cap B) = P(A) \cdot P(B)$\\
$P(A|B) = \frac{P(A \cap B)}{P(B)}$\\

\textbf{Satz der totalen Wahrscheinlichkeit}

$P(B) = \sum_{i=1}^m P(A_i) P(B|A_i) = \sum_{i=1}^m P(A_i \cap B)$\\

\textbf{Satz von Bayes}

$P(A_k|B) = \frac{P(A)}{P(B)} \cdot P(B|A_k) = \frac{P(A_k) P(B|A_k)}{\sum_{i=1}^m P(A_i) P(B|A_i)}$\\

\textbf{Zufallsvariablen}

$X: \Omega \rightarrow R$\\
$P(X=k) = P(X(\omega)=k)$\\

\textbf{Verteilungsfunktion}

$F(t) = P({\omega \in \Omega: X(\omega \leq t)}) = P(X \leq t)$\\
(1) mon. wachsend (2) $lim_{x\searrow x^*}F(x)=F(x^*)$\\
(3) $lim_{x\searrow x^*}F(x)-lim_{x\nearrow x^*}F(x)=P(X=x^*)$\\
$P(x < X \leq y) = F(y) - F(x)$\\

\textbf{Quantil}

$lim_{x\nearrow Q_p}F(x) \leq p \leq F(Q_p)$\\

\textbf{Binomialkoeffizienten}

$\binom{n}{k} = \frac{n!}{k!(n-k)!}$\\
$\binom{n}{k} = 0$ für k>n\\
$\binom{n}{0} = 1$; $\binom{n}{1} = n$\\

\textbf{Binomialverteilung}

$P(X=k) = \binom{n}{k}p^k(1-p)^{n-k}$\\
$\mu = np$\\
$\sigma = \sqrt{np(1-p)}$\\
$F(t) \approx \Phi(\frac{t+0,5-\mu}{\sigma})$ bei $np(1-p) \geq 9$

\textbf{Hypergeometrische Verteilung}

$P(X=k) = \frac{\binom{M}{k}\binom{N-M}{n-k}}{\binom{N}{n}}$\\

\textbf{Poisson Verteilung}

\textbf{Verteilungsfunktion}

$F(t) = \int_{-\infty}^t f(x) dx$

\textbf{E und Var}

$Var(X) = E(X^2) - E(X)^2$\\
$E(X) = \int_{-\infty}^{\infty} xf(x) dx$

\textbf{Normalverteilung}

$F(x) = \Phi(\frac{x-\mu}{\sigma})$\\
$\Phi(-t) = 1-\Phi(t)$

\textbf{Gleichverteilung auf [a,b]}

$f(x) = \frac{1}{b-a}$ für $x \in (a,b)$ sonst 0\\
$E(X) = \frac{b+a}{2}$\\
$V(X) = \frac{(b-a)^2}{12}$

\textbf{Exponentialverteilung}

$f(x) = \lambda e^{-\lambda x}$ für $x \geq 0$ sonst 0\\
$F(t) = 1-e^{-\lambda t}$ für $t \geq 0$ sonst 0\\
$E(X) = \frac{1}{\lambda}$; $V(X) = \frac{1}{\lambda^2}$\\

\textbf{Stichprobengrößen}

$\bar{x} = \frac{1}{n} \sum_{i=1}^{n}x_i$\\
$\bar{s}_x^2 = \frac{1}{n-1} \sum_{i=1}^{n}(x_i-\bar{x})^2$\\
emp. Korrelation: $s_{x,y} = \frac{1}{n-1} \sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})$\\

\textbf{Konfidenzintervalle}

$[\bar{X}-\sigma z_{1-\alpha/2}/\sqrt{n}, \bar{X}+\sigma z_{1-\alpha/2}/\sqrt{n}]$\\
$(-\infty, \bar{X}+\sigma z_{1-\alpha}/\sqrt{n}]$\\
$[\bar{X} - t_{n-1,1-\alpha/2}\bar{S}/\sqrt{n}, \bar{X} + t_{n-1,1-\alpha/2}\bar{S}/\sqrt{n}]$\\
$[\frac{(n-1)\bar{S}^2}{c_{n-1,1-\alpha/2}},\frac{(n-1)\bar{S}^2}{c_{n-1,\textcolor{red}{\alpha/2}}}]$ (für Varianz)\\
$[\frac{k}{n}-\frac{z_{1-\alpha/2}}{\sqrt{n}}\sqrt{\frac{k}{n}(1-\frac{k}{n})}, \frac{k}{n}+..]$ (für B mit k,n-k>50)\\

\textbf{Hypothesentest Erwartungswert}

$H_0: \mu > \mu_0$; $\bar{H_0}: \mu \leq \mu_0$\\
$P(A_0|\bar{H_0})$ = $P(\frac{Z-\mu_0}{\sigma/\sqrt{n}} \geq k) \leq \alpha$\\

\textbf{Hypothesentest Varianz}

$H_0: \sigma^2 > \sigma_0^2$; $\bar{H_0}: \sigma^2 \leq \sigma_0^2$\\
$P(A_0|\bar{H_0}) = P(\frac{(n-1)Z}{\sigma^2} \geq k) \leq \alpha$\\

\textbf{Lagrange-Interpolation}

$L_i(x) = \prod_{j=0;j \ne i}^n \frac{x-x_j}{x_i-x_j}$\\
$P_n(x) = \sum_{i=0}^n y_i L_i(x)$\\

\textbf{Newton-Interpolation}

$P_n(x) = \sum_{i=0}^n \alpha_{i,i} \prod_{j=0}^{i-1}(x-x_j)$\\
$\alpha_{i,0} = y_i$; $\alpha_{i,j} = \frac{\alpha_{i,j-1} - \alpha_{i-1,j-1}}{x_i - x_{i-j}}$\\

\textbf{Neville-Interpolation}

$P_{i,0}(x) = y_i$\\
$P_{i,j}(x) = \frac{(x-x_{i-j})P_{i,j-1}(x) - (x-x_i)P_{i-1,j-1}(x)}{x_i - x_{i-j}}$\\

\textbf{Newton-Cotes-Formel}

$\int_a^b f(x) dx \approx h \sum_{i=0}^n \alpha_i f(x_i)$ mit $h=\frac{b-a}{h}$; $x_i = a + hi$\\
$\alpha_i = \int_0^n \Pi_{j=0;j\neq i}^n \frac{t-j}{i-j} dt$\\

\textbf{Newtonverfahren}

$x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}$\\
$x_{n+1} = x_n - \frac{x_n - x_{n-1}}{f(x_n) - f(x_{n-1})} \cdot f(x_n)$\\

\textbf{strikt diagonaldominant}

$\forall j = 1,..,n: |a_{\textcolor{red}{ii}}| > \sum_{i=1,i\neq j}^n |a_{\textcolor{red}{ji}}|$\\
J- und G-S-Verfahren konvergieren hier gegen Lösung\\

\textbf{Jacobiverfahren}

$A = L + U + D$ L: Lower, U: Upper, D: Diag.\\
$x_{k+1} := D^{-1}(b-(L+U)x_k)$\\

\textbf{Gauß-Seidel-Verfahren}

$x_{k+1} = (D+L)^{-1} (b-Ux_k)$\\

\textbf{LU-Faktorisierung}

$A = PLU$, L: untere DM mit 1 auf Diag., P: Permut.\\
$U_0 = A$, $L_0 = E_n$\\
Pivot: \\

\textbf{Cholesky-Zerlegung}

A muss symmetrisch und positiv definit sein\\
in Praxis: symmetrisch und dann probieren, ob Verfahren funktioniert\\
$A = GG^T$, G - untere Dreiecksmatrix\\
$g_{jj} = \sqrt{a_{jj} - \sum_{k=1}^{j-1} g_{jk}^2}$\\
$g_{ij} = \frac{1}{g_{jj}} (a_{ij} - \sum_{k=1}^{j-1} g_{ik}g_{jk}), i=j+1,..,n$\\
zeilenweise von links nach rechts\\
Lösen GS: $GG^Tx=b$, $y:=G^Tx$\\
1) y aus $Gy=b$ 2) x aus $G^Tx=y$\\

\textbf{QR-Zerlegung}

$A = QR$\\
$u_i = a_i - \sum_{j=1}^{i-1} \frac{<u_j, a_{\textcolor{red}{i}}>}{||u_j||^2}u_j$\\
$q_i = u_i / ||u_i||$, $r_{ij} = \frac{<u_i, a_j>}{||u_i||}, 1 \leq i \leq j \leq n$\\




\textbf{Differenzieren und Integrieren}

\textbf{Werte von Sinus/Cosinus}




\end{flushleft}
\end{document}
